{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconhecimento Facial utilizando um modelo pré-treinado\n",
    "\n",
    "\n",
    "A implementação é inspirada em dois artigos inovadores sobre reconhecimento facial usando redes neurais convolucionais, nomeadas de FaceNet e DeepFace.\n",
    "\n",
    "Foi utilizado o modelo pré-treinado Keras-OpenFace , que é uma implementação open source do OpenFace no Keras (Implementado originalmente no PyTorch)\n",
    "\n",
    "O modelo pré-treinado utilizado foi a implementação do Victor Sy Wang's, e foi carregado com o seguinte código:\n",
    "https://github.com/iwantooxxoox/Keras-OpenFace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importação das bibliotecas\n",
    "\n",
    "Importar o arquivo utils.py do https://github.com/iwantooxxoox/Keras-OpenFace/blob/master/utils.py no qual contém funções utéis para a criação da rede neural e carregar seus pesos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers.core import Lambda, Flatten, Dense\n",
    "from keras.engine.topology import Layer\n",
    "from keras import backend as K\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "from matplotlib import pyplot\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from utils import LRN2D\n",
    "import utils\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#np.set_printoptions(threshold=np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construção da Rede Neural\n",
    "\n",
    "O modelo implementado é baseado no modelo FaceNet.\n",
    "\n",
    "A implementação do modelo está disponível aqui: https://github.com/iwantooxxoox/Keras-OpenFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\monoc\\AppData\\Local\\Continuum\\anaconda3\\envs\\py36-2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\monoc\\AppData\\Local\\Continuum\\anaconda3\\envs\\py36-2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4074: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "myInput = Input(shape=(96, 96, 3))\n",
    "\n",
    "x = ZeroPadding2D(padding=(3, 3), input_shape=(96, 96, 3))(myInput)\n",
    "x = Conv2D(64, (7, 7), strides=(2, 2), name='conv1')(x)\n",
    "x = BatchNormalization(axis=3, epsilon=0.00001, name='bn1')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = ZeroPadding2D(padding=(1, 1))(x)\n",
    "x = MaxPooling2D(pool_size=3, strides=2)(x)\n",
    "x = Lambda(LRN2D, name='lrn_1')(x)\n",
    "x = Conv2D(64, (1, 1), name='conv2')(x)\n",
    "x = BatchNormalization(axis=3, epsilon=0.00001, name='bn2')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = ZeroPadding2D(padding=(1, 1))(x)\n",
    "x = Conv2D(192, (3, 3), name='conv3')(x)\n",
    "x = BatchNormalization(axis=3, epsilon=0.00001, name='bn3')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Lambda(LRN2D, name='lrn_2')(x)\n",
    "x = ZeroPadding2D(padding=(1, 1))(x)\n",
    "x = MaxPooling2D(pool_size=3, strides=2)(x)\n",
    "\n",
    "# Inception3a\n",
    "inception_3a_3x3 = Conv2D(96, (1, 1), name='inception_3a_3x3_conv1')(x)\n",
    "inception_3a_3x3 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3a_3x3_bn1')(inception_3a_3x3)\n",
    "inception_3a_3x3 = Activation('relu')(inception_3a_3x3)\n",
    "inception_3a_3x3 = ZeroPadding2D(padding=(1, 1))(inception_3a_3x3)\n",
    "inception_3a_3x3 = Conv2D(128, (3, 3), name='inception_3a_3x3_conv2')(inception_3a_3x3)\n",
    "inception_3a_3x3 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3a_3x3_bn2')(inception_3a_3x3)\n",
    "inception_3a_3x3 = Activation('relu')(inception_3a_3x3)\n",
    "\n",
    "inception_3a_5x5 = Conv2D(16, (1, 1), name='inception_3a_5x5_conv1')(x)\n",
    "inception_3a_5x5 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3a_5x5_bn1')(inception_3a_5x5)\n",
    "inception_3a_5x5 = Activation('relu')(inception_3a_5x5)\n",
    "inception_3a_5x5 = ZeroPadding2D(padding=(2, 2))(inception_3a_5x5)\n",
    "inception_3a_5x5 = Conv2D(32, (5, 5), name='inception_3a_5x5_conv2')(inception_3a_5x5)\n",
    "inception_3a_5x5 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3a_5x5_bn2')(inception_3a_5x5)\n",
    "inception_3a_5x5 = Activation('relu')(inception_3a_5x5)\n",
    "\n",
    "inception_3a_pool = MaxPooling2D(pool_size=3, strides=2)(x)\n",
    "inception_3a_pool = Conv2D(32, (1, 1), name='inception_3a_pool_conv')(inception_3a_pool)\n",
    "inception_3a_pool = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3a_pool_bn')(inception_3a_pool)\n",
    "inception_3a_pool = Activation('relu')(inception_3a_pool)\n",
    "inception_3a_pool = ZeroPadding2D(padding=((3, 4), (3, 4)))(inception_3a_pool)\n",
    "\n",
    "inception_3a_1x1 = Conv2D(64, (1, 1), name='inception_3a_1x1_conv')(x)\n",
    "inception_3a_1x1 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3a_1x1_bn')(inception_3a_1x1)\n",
    "inception_3a_1x1 = Activation('relu')(inception_3a_1x1)\n",
    "\n",
    "inception_3a = concatenate([inception_3a_3x3, inception_3a_5x5, inception_3a_pool, inception_3a_1x1], axis=3)\n",
    "\n",
    "# Inception3b\n",
    "inception_3b_3x3 = Conv2D(96, (1, 1), name='inception_3b_3x3_conv1')(inception_3a)\n",
    "inception_3b_3x3 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3b_3x3_bn1')(inception_3b_3x3)\n",
    "inception_3b_3x3 = Activation('relu')(inception_3b_3x3)\n",
    "inception_3b_3x3 = ZeroPadding2D(padding=(1, 1))(inception_3b_3x3)\n",
    "inception_3b_3x3 = Conv2D(128, (3, 3), name='inception_3b_3x3_conv2')(inception_3b_3x3)\n",
    "inception_3b_3x3 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3b_3x3_bn2')(inception_3b_3x3)\n",
    "inception_3b_3x3 = Activation('relu')(inception_3b_3x3)\n",
    "\n",
    "inception_3b_5x5 = Conv2D(32, (1, 1), name='inception_3b_5x5_conv1')(inception_3a)\n",
    "inception_3b_5x5 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3b_5x5_bn1')(inception_3b_5x5)\n",
    "inception_3b_5x5 = Activation('relu')(inception_3b_5x5)\n",
    "inception_3b_5x5 = ZeroPadding2D(padding=(2, 2))(inception_3b_5x5)\n",
    "inception_3b_5x5 = Conv2D(64, (5, 5), name='inception_3b_5x5_conv2')(inception_3b_5x5)\n",
    "inception_3b_5x5 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3b_5x5_bn2')(inception_3b_5x5)\n",
    "inception_3b_5x5 = Activation('relu')(inception_3b_5x5)\n",
    "\n",
    "inception_3b_pool = Lambda(lambda x: x**2, name='power2_3b')(inception_3a)\n",
    "inception_3b_pool = AveragePooling2D(pool_size=(3, 3), strides=(3, 3))(inception_3b_pool)\n",
    "inception_3b_pool = Lambda(lambda x: x*9, name='mult9_3b')(inception_3b_pool)\n",
    "inception_3b_pool = Lambda(lambda x: K.sqrt(x), name='sqrt_3b')(inception_3b_pool)\n",
    "inception_3b_pool = Conv2D(64, (1, 1), name='inception_3b_pool_conv')(inception_3b_pool)\n",
    "inception_3b_pool = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3b_pool_bn')(inception_3b_pool)\n",
    "inception_3b_pool = Activation('relu')(inception_3b_pool)\n",
    "inception_3b_pool = ZeroPadding2D(padding=(4, 4))(inception_3b_pool)\n",
    "\n",
    "inception_3b_1x1 = Conv2D(64, (1, 1), name='inception_3b_1x1_conv')(inception_3a)\n",
    "inception_3b_1x1 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3b_1x1_bn')(inception_3b_1x1)\n",
    "inception_3b_1x1 = Activation('relu')(inception_3b_1x1)\n",
    "\n",
    "inception_3b = concatenate([inception_3b_3x3, inception_3b_5x5, inception_3b_pool, inception_3b_1x1], axis=3)\n",
    "\n",
    "# Inception3c\n",
    "inception_3c_3x3 = utils.conv2d_bn(inception_3b,\n",
    "                                   layer='inception_3c_3x3',\n",
    "                                   cv1_out=128,\n",
    "                                   cv1_filter=(1, 1),\n",
    "                                   cv2_out=256,\n",
    "                                   cv2_filter=(3, 3),\n",
    "                                   cv2_strides=(2, 2),\n",
    "                                   padding=(1, 1))\n",
    "\n",
    "inception_3c_5x5 = utils.conv2d_bn(inception_3b,\n",
    "                                   layer='inception_3c_5x5',\n",
    "                                   cv1_out=32,\n",
    "                                   cv1_filter=(1, 1),\n",
    "                                   cv2_out=64,\n",
    "                                   cv2_filter=(5, 5),\n",
    "                                   cv2_strides=(2, 2),\n",
    "                                   padding=(2, 2))\n",
    "\n",
    "inception_3c_pool = MaxPooling2D(pool_size=3, strides=2)(inception_3b)\n",
    "inception_3c_pool = ZeroPadding2D(padding=((0, 1), (0, 1)))(inception_3c_pool)\n",
    "\n",
    "inception_3c = concatenate([inception_3c_3x3, inception_3c_5x5, inception_3c_pool], axis=3)\n",
    "\n",
    "#inception 4a\n",
    "inception_4a_3x3 = utils.conv2d_bn(inception_3c,\n",
    "                                   layer='inception_4a_3x3',\n",
    "                                   cv1_out=96,\n",
    "                                   cv1_filter=(1, 1),\n",
    "                                   cv2_out=192,\n",
    "                                   cv2_filter=(3, 3),\n",
    "                                   cv2_strides=(1, 1),\n",
    "                                   padding=(1, 1))\n",
    "inception_4a_5x5 = utils.conv2d_bn(inception_3c,\n",
    "                                   layer='inception_4a_5x5',\n",
    "                                   cv1_out=32,\n",
    "                                   cv1_filter=(1, 1),\n",
    "                                   cv2_out=64,\n",
    "                                   cv2_filter=(5, 5),\n",
    "                                   cv2_strides=(1, 1),\n",
    "                                   padding=(2, 2))\n",
    "\n",
    "inception_4a_pool = Lambda(lambda x: x**2, name='power2_4a')(inception_3c)\n",
    "inception_4a_pool = AveragePooling2D(pool_size=(3, 3), strides=(3, 3))(inception_4a_pool)\n",
    "inception_4a_pool = Lambda(lambda x: x*9, name='mult9_4a')(inception_4a_pool)\n",
    "inception_4a_pool = Lambda(lambda x: K.sqrt(x), name='sqrt_4a')(inception_4a_pool)\n",
    "inception_4a_pool = utils.conv2d_bn(inception_4a_pool,\n",
    "                                   layer='inception_4a_pool',\n",
    "                                   cv1_out=128,\n",
    "                                   cv1_filter=(1, 1),\n",
    "                                   padding=(2, 2))\n",
    "inception_4a_1x1 = utils.conv2d_bn(inception_3c,\n",
    "                                   layer='inception_4a_1x1',\n",
    "                                   cv1_out=256,\n",
    "                                   cv1_filter=(1, 1))\n",
    "inception_4a = concatenate([inception_4a_3x3, inception_4a_5x5, inception_4a_pool, inception_4a_1x1], axis=3)\n",
    "\n",
    "#inception4e\n",
    "inception_4e_3x3 = utils.conv2d_bn(inception_4a,\n",
    "                                   layer='inception_4e_3x3',\n",
    "                                   cv1_out=160,\n",
    "                                   cv1_filter=(1, 1),\n",
    "                                   cv2_out=256,\n",
    "                                   cv2_filter=(3, 3),\n",
    "                                   cv2_strides=(2, 2),\n",
    "                                   padding=(1, 1))\n",
    "inception_4e_5x5 = utils.conv2d_bn(inception_4a,\n",
    "                                   layer='inception_4e_5x5',\n",
    "                                   cv1_out=64,\n",
    "                                   cv1_filter=(1, 1),\n",
    "                                   cv2_out=128,\n",
    "                                   cv2_filter=(5, 5),\n",
    "                                   cv2_strides=(2, 2),\n",
    "                                   padding=(2, 2))\n",
    "inception_4e_pool = MaxPooling2D(pool_size=3, strides=2)(inception_4a)\n",
    "inception_4e_pool = ZeroPadding2D(padding=((0, 1), (0, 1)))(inception_4e_pool)\n",
    "\n",
    "inception_4e = concatenate([inception_4e_3x3, inception_4e_5x5, inception_4e_pool], axis=3)\n",
    "\n",
    "#inception5a\n",
    "inception_5a_3x3 = utils.conv2d_bn(inception_4e,\n",
    "                                   layer='inception_5a_3x3',\n",
    "                                   cv1_out=96,\n",
    "                                   cv1_filter=(1, 1),\n",
    "                                   cv2_out=384,\n",
    "                                   cv2_filter=(3, 3),\n",
    "                                   cv2_strides=(1, 1),\n",
    "                                   padding=(1, 1))\n",
    "\n",
    "inception_5a_pool = Lambda(lambda x: x**2, name='power2_5a')(inception_4e)\n",
    "inception_5a_pool = AveragePooling2D(pool_size=(3, 3), strides=(3, 3))(inception_5a_pool)\n",
    "inception_5a_pool = Lambda(lambda x: x*9, name='mult9_5a')(inception_5a_pool)\n",
    "inception_5a_pool = Lambda(lambda x: K.sqrt(x), name='sqrt_5a')(inception_5a_pool)\n",
    "inception_5a_pool = utils.conv2d_bn(inception_5a_pool,\n",
    "                                   layer='inception_5a_pool',\n",
    "                                   cv1_out=96,\n",
    "                                   cv1_filter=(1, 1),\n",
    "                                   padding=(1, 1))\n",
    "inception_5a_1x1 = utils.conv2d_bn(inception_4e,\n",
    "                                   layer='inception_5a_1x1',\n",
    "                                   cv1_out=256,\n",
    "                                   cv1_filter=(1, 1))\n",
    "\n",
    "inception_5a = concatenate([inception_5a_3x3, inception_5a_pool, inception_5a_1x1], axis=3)\n",
    "\n",
    "#inception_5b\n",
    "inception_5b_3x3 = utils.conv2d_bn(inception_5a,\n",
    "                                   layer='inception_5b_3x3',\n",
    "                                   cv1_out=96,\n",
    "                                   cv1_filter=(1, 1),\n",
    "                                   cv2_out=384,\n",
    "                                   cv2_filter=(3, 3),\n",
    "                                   cv2_strides=(1, 1),\n",
    "                                   padding=(1, 1))\n",
    "inception_5b_pool = MaxPooling2D(pool_size=3, strides=2)(inception_5a)\n",
    "inception_5b_pool = utils.conv2d_bn(inception_5b_pool,\n",
    "                                   layer='inception_5b_pool',\n",
    "                                   cv1_out=96,\n",
    "                                   cv1_filter=(1, 1))\n",
    "inception_5b_pool = ZeroPadding2D(padding=(1, 1))(inception_5b_pool)\n",
    "\n",
    "inception_5b_1x1 = utils.conv2d_bn(inception_5a,\n",
    "                                   layer='inception_5b_1x1',\n",
    "                                   cv1_out=256,\n",
    "                                   cv1_filter=(1, 1))\n",
    "inception_5b = concatenate([inception_5b_3x3, inception_5b_pool, inception_5b_1x1], axis=3)\n",
    "\n",
    "av_pool = AveragePooling2D(pool_size=(3, 3), strides=(1, 1))(inception_5b)\n",
    "reshape_layer = Flatten()(av_pool)\n",
    "dense_layer = Dense(128, name='dense_layer')(reshape_layer)\n",
    "norm_layer = Lambda(lambda  x: K.l2_normalize(x, axis=1), name='norm_layer')(dense_layer)\n",
    "\n",
    "\n",
    "# Final Model\n",
    "model = Model(inputs=[myInput], outputs=norm_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregar o modelo com pesos pré-treinados\n",
    "\n",
    "A FaceNet é treinado minimizado o triplet loss. Será carregado um modelo previamente treinado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = utils.weights\n",
    "weights_dict = utils.load_weights()\n",
    "\n",
    "# Set layer weights of the model\n",
    "for name in weights:\n",
    "  if model.get_layer(name) != None:\n",
    "    model.get_layer(name).set_weights(weights_dict[name])\n",
    "  elif model.get_layer(name) != None:\n",
    "    model.get_layer(name).set_weights(weights_dict[name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função <font color=blue>image_to_embedding</font>\n",
    "\n",
    "Quando o modelo é carregado com pesos pré-treinados, pode-se criar os **128 vetores dimensionais embedding** para todas as faces salvas na pasta \"images\".\n",
    "\n",
    "A função **\"image_to_embedding\"** passa uma imagem pro modelo Inception, para gerar os vetores embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_embedding(image, model):\n",
    "    #image = cv2.resize(image, (96, 96), interpolation=cv2.INTER_AREA) \n",
    "    image = cv2.resize(image, (96, 96)) \n",
    "    img = image[...,::-1]\n",
    "    img = np.around(np.transpose(img, (0,1,2))/255.0, decimals=12)\n",
    "    x_train = np.array([img])\n",
    "    embedding = model.predict_on_batch(x_train)\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função <font color=blue>recognize_face</font>\n",
    "\n",
    "Essa função calcula a similaridade entre a imagem capturado e as imagens que já estão armazenadas. Passa a imagem para o modelo de rede neural pré-treinado para gerar o vetor embedding. Este vetor será comparado com todos os outros vetores embeddings das imagens salvas, por meio da distância euclidiana L2.\n",
    "\n",
    "Se a mínima distância de L2 entre dois vetores embedding for menor do que o treshold (aqui o valor de treshold foi de .68, podendo ser ajustado) então serão correspondentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_face(face_image, input_embeddings, model):\n",
    "\n",
    "    embedding = image_to_embedding(face_image, model)\n",
    "    \n",
    "    minimum_distance = 200\n",
    "    name = None\n",
    "    \n",
    "    for(input_name, input_embedding) in input_embeddings.items():    \n",
    "        euclidean_distance = np.linalg.norm(embedding-input_embedding)\n",
    "#         print('Euclidean distance from %s is %s' %(input_name, euclidean_distance))\n",
    "\n",
    "        if(euclidean_distance < minimum_distance):\n",
    "            minimum_distance = euclidean_distance\n",
    "            name = input_name\n",
    "    \n",
    "    if(minimum_distance < 0.68):\n",
    "        return str(name)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função <font color=blue>create_input_image_embeddings</font>\n",
    "\n",
    "Essa função gera imagens embedding com dimensão de 128 para todas as imagens salvas na pasta \"images\" atráves da rede neural treinada. Cria um dicionário com o nome da imagem sendo a chave e os valores sendo o embedding.\n",
    "\n",
    "## Função <font color=blue>recognize_faces_in_cam</font>\n",
    "\n",
    "Essa função captura a imagem através da webcam, detectar a face e cortar a imagem para ter somente a face, em seguida é passada para a função <font color=blue>recognize_face</font>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import re\n",
    "\n",
    "def create_input_image_embeddings():\n",
    "    input_embeddings = {}\n",
    "\n",
    "    for file in glob.glob(\"images/*/*.jpg\"):\n",
    "        person_name = os.path.splitext(os.path.basename(file))[0]\n",
    "        person_name = re.search(r'(\\D+)\\_', person_name)\n",
    "        person_name = person_name.group(1)\n",
    "        image_file = cv2.imread(file, 1)\n",
    "        input_embeddings[person_name] = image_to_embedding(image_file, model)\n",
    "\n",
    "    return input_embeddings\n",
    "\n",
    "def recognize_faces_in_cam(input_embeddings):\n",
    "    \n",
    "\n",
    "    cv2.namedWindow(\"Face Recognizer\")\n",
    "    vc = cv2.VideoCapture(0)\n",
    "   \n",
    "\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    \n",
    "    # Cascade Classifier OpenCV\n",
    "#     face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "    \n",
    "    #MultiTask CNN\n",
    "    face_detector = MTCNN()\n",
    "    \n",
    "    while vc.isOpened():\n",
    "        _, frame = vc.read()\n",
    "        img = frame\n",
    "        height, width, channels = frame.shape\n",
    "        \n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "#         faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "        faces = face_detector.detect_faces(img)\n",
    "        \n",
    "        # Loop through all the faces detected \n",
    "        identities = []\n",
    "#         for (x, y, w, h) in faces:\n",
    "#             x1 = x\n",
    "#             y1 = y\n",
    "#             x2 = x+w\n",
    "#             y2 = y+h\n",
    "\n",
    "        for i in range(len(faces)):\n",
    "            x1, y1, w, h = faces[i]['box']\n",
    "            x2, y2 = x1 + w, y1 + h\n",
    "            \n",
    "            face_image = frame[max(0, y1):min(height, y2), max(0, x1):min(width, x2)]    \n",
    "            identity = recognize_face(face_image, input_embeddings, model)\n",
    "\n",
    "            if identity is not None:\n",
    "                img = cv2.rectangle(frame,(x1, y1),(x2, y2),(255,255,255),2)\n",
    "                cv2.putText(img, str(identity), (x1+5,y1-5), font, 1, (255,255,255), 2)\n",
    "        \n",
    "        key = cv2.waitKey(100)\n",
    "        cv2.imshow(\"Face Recognizer\", img)\n",
    "\n",
    "        if key == 27: #saída no ESC\n",
    "            break\n",
    "    vc.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interface Tkinter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk \n",
    "\n",
    "dir_name = \"\"\n",
    "\n",
    "def start_app():    \n",
    "    master = tk.Tk()\n",
    "    master.title(\"Smart Glass\")\n",
    "\n",
    "    tk.Label(master, text='Nome').grid(row=0) \n",
    "    tk.Label(master, text='Sobrenome').grid(row=1) \n",
    "\n",
    "    name = tk.Entry(master) \n",
    "    last_name = tk.Entry(master) \n",
    "    name.grid(row=0, column=1) \n",
    "    last_name.grid(row=1, column=1) \n",
    "\n",
    "    def callback(event=None):\n",
    "        global dir_name\n",
    "        dir_name = name.get() + last_name.get()\n",
    "        master.destroy()\n",
    "\n",
    "    btn = tk.Button(master, text = \"OK\", width=10, command = callback)\n",
    "    btn.grid(row=2, column=1)\n",
    "\n",
    "    master.bind(\"<Return>\", callback)\n",
    "    master.lift()\n",
    "    master.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capturar faces\n",
    "\n",
    "O seguinte código captura 10 imagens de uma pessoa. Elas são salvas na pasta \"images\" com o nome de User_1 até User_10. Selecione a melhor imagem das 10. Renomeie a foto com o nome dela, e apague o resto das imagens. Essa imagem será utilizada para reconhecer a face da pessoa através do One Shot Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cascade Classifier OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "face_detector = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "count = 0\n",
    "while(True):\n",
    "    ret, img = cam.read()\n",
    "    faces = face_detector.detectMultiScale(img, 1.3, 5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        x1 = x\n",
    "        y1 = y\n",
    "        x2 = x+w\n",
    "        y2 = y+h\n",
    "        cv2.rectangle(img, (x1,y1), (x2,y2), (255,255,255), 2)     \n",
    "        count += 1\n",
    "        # Salvar as imagens dentro da pasta 'images'\n",
    "        cv2.imwrite(\"images/User_\" + str(count) + \".jpg\", img[y1:y2,x1:x2])\n",
    "        cv2.imshow('image', img)\n",
    "    k = cv2.waitKey(200) & 0xff #saída no ESC\n",
    "    if k == 27:\n",
    "        break\n",
    "    elif count >= 10:\n",
    "         break\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultiTask CNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_app()\n",
    "\n",
    "try:\n",
    "    os.mkdir(\"images/{}/\".format(dir_name))\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "face_detector = MTCNN()\n",
    "\n",
    "count = 0\n",
    "while(True):\n",
    "    ret, img = cam.read()\n",
    "    faces = face_detector.detect_faces(img)\n",
    "    for i in range(len(faces)):\n",
    "        x1, y1, width, height = faces[i]['box']\n",
    "        x2, y2 = x1 + width, y1 + height\n",
    "        cv2.rectangle(img, (x1,y1), (x2,y2), (255,255,255), 2)     \n",
    "        count += 1\n",
    "        # Salvar as imagens dentro da pasta 'images'\n",
    "        cv2.imwrite(\"images/{}/{}_\".format(dir_name, dir_name) + str(count) + \".jpg\", img[y1:y2,x1:x2])\n",
    "        cv2.imshow('image', img)\n",
    "    k = cv2.waitKey(200) & 0xff #saída no ESC\n",
    "    if k == 27:\n",
    "        break\n",
    "    elif count >= 10:\n",
    "         break\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DinhoSoares': array([[ 0.04802728,  0.03750252, -0.08263657,  0.00491131, -0.01768545,\n",
       "          0.14761376, -0.06787279, -0.03890521, -0.0056197 , -0.13087645,\n",
       "          0.08630715,  0.14676256,  0.0527203 , -0.11067671, -0.18464951,\n",
       "          0.00869838, -0.08495291,  0.05536461, -0.14349858,  0.15115435,\n",
       "          0.12760827, -0.03926608,  0.08891631,  0.02342255, -0.0901574 ,\n",
       "          0.01725823,  0.05596548, -0.13844149, -0.13461116,  0.07922625,\n",
       "         -0.06501531, -0.03172664,  0.08975697,  0.12704276, -0.02692638,\n",
       "          0.01741591, -0.00755119,  0.12259854, -0.08028157, -0.0027083 ,\n",
       "         -0.06212519, -0.07960817,  0.01564151,  0.09065685, -0.10148361,\n",
       "         -0.08002614,  0.1612622 , -0.0888348 , -0.17039587,  0.21055299,\n",
       "          0.06244998, -0.0820504 , -0.09251866,  0.12719445,  0.10222878,\n",
       "          0.01857189, -0.02337919,  0.03063533, -0.06617044, -0.09275288,\n",
       "         -0.05792993, -0.04702435,  0.21706247, -0.13601862,  0.11291526,\n",
       "         -0.16156003, -0.04933817,  0.02388675, -0.13810584,  0.13874476,\n",
       "          0.02097389, -0.07398585, -0.0385646 , -0.02845299,  0.00451865,\n",
       "          0.02834315,  0.00844167, -0.00817002, -0.05510528,  0.03057055,\n",
       "         -0.09865605, -0.01705174,  0.00731641, -0.0029555 , -0.17363726,\n",
       "          0.07133234,  0.02970818, -0.02506686,  0.05346771,  0.10703371,\n",
       "         -0.01282856, -0.27448806, -0.06399098,  0.03344199, -0.00366686,\n",
       "          0.0135472 , -0.05675207,  0.06827551, -0.02355056,  0.01444909,\n",
       "         -0.01195535,  0.0685771 , -0.10677113,  0.08664316,  0.04334909,\n",
       "          0.04297493, -0.07170423,  0.07240729, -0.14705704, -0.10915803,\n",
       "         -0.05743192,  0.05544371, -0.00483193,  0.06620679,  0.01998411,\n",
       "          0.03962285, -0.01303378, -0.06201554,  0.07408123,  0.14761391,\n",
       "          0.02575104, -0.00446517,  0.05405972,  0.01053431,  0.1365587 ,\n",
       "          0.03098652,  0.14658543, -0.00030335]], dtype=float32),\n",
       " 'KidMendes': array([[-0.01047827,  0.16761579,  0.05966552, -0.05167896, -0.00032432,\n",
       "          0.25686997, -0.02822698,  0.02503126, -0.04554642, -0.15780878,\n",
       "         -0.02552079, -0.04237584,  0.00302029, -0.15184036, -0.02130425,\n",
       "         -0.01989322, -0.14726017, -0.05856109, -0.12289583, -0.01780436,\n",
       "          0.12255759, -0.03008022,  0.03067723, -0.06529957,  0.03280242,\n",
       "         -0.01085783, -0.06431585, -0.09724846,  0.02902049, -0.06236811,\n",
       "          0.14093517, -0.02247971, -0.05245625,  0.12120288,  0.06538489,\n",
       "          0.01979316,  0.04332955,  0.08800919,  0.02314225, -0.05297982,\n",
       "          0.09632724, -0.1267404 ,  0.09004039,  0.05921903, -0.0358398 ,\n",
       "         -0.05251674,  0.1471757 , -0.02630306, -0.2518447 ,  0.04679798,\n",
       "         -0.07797641, -0.05495711, -0.00383145,  0.05388145,  0.03435172,\n",
       "          0.045618  , -0.06529129,  0.0934837 , -0.06591284, -0.21118982,\n",
       "         -0.10522103,  0.05433546,  0.17263116, -0.17774974,  0.14339799,\n",
       "          0.07775279,  0.01316007, -0.0310523 , -0.12912084,  0.1238756 ,\n",
       "         -0.04743287, -0.01481932, -0.05601057,  0.0193453 ,  0.08581024,\n",
       "         -0.05825127, -0.03630055, -0.02094334,  0.02391191,  0.06589043,\n",
       "         -0.08227929, -0.00761992,  0.06494659,  0.00060741, -0.08900043,\n",
       "         -0.00772855,  0.03667947,  0.0377669 ,  0.01640326,  0.11663054,\n",
       "          0.15307143, -0.21252412, -0.05859162, -0.00993102, -0.00749921,\n",
       "          0.01953196,  0.03924983,  0.13836564, -0.07789154,  0.06071138,\n",
       "         -0.07766635,  0.04383483, -0.10967502,  0.10111596, -0.02911871,\n",
       "          0.09418854, -0.03155956,  0.1308013 , -0.05243128, -0.13117145,\n",
       "          0.00499222,  0.06594204, -0.12364187,  0.04916222,  0.1313938 ,\n",
       "         -0.03233858, -0.09200756, -0.04194622,  0.13241866,  0.11482678,\n",
       "          0.09820782, -0.01991043,  0.06712384,  0.00828584,  0.11514539,\n",
       "         -0.01461519,  0.12757784, -0.03238506]], dtype=float32),\n",
       " 'LarissaGuimaraes': array([[ 7.53022507e-02, -2.21562833e-02, -1.09372295e-01,\n",
       "         -8.67003426e-02,  8.65301043e-02,  1.96493939e-01,\n",
       "          5.00591472e-02, -1.74001828e-02, -5.40546402e-02,\n",
       "         -9.29911509e-02, -9.21742097e-02,  6.72000945e-02,\n",
       "          1.08899921e-01, -1.88039225e-02, -3.88157628e-02,\n",
       "         -3.79771665e-02, -1.04959279e-01, -4.31211330e-02,\n",
       "         -1.33604899e-01,  1.22114621e-01,  8.18349496e-02,\n",
       "          4.12994064e-03,  4.00537699e-02,  7.72525221e-02,\n",
       "         -9.77142975e-02,  2.12405510e-02, -5.93728684e-02,\n",
       "         -1.91472247e-01, -9.54503864e-02,  6.37473390e-02,\n",
       "         -4.40162271e-02,  4.68516015e-02, -1.12755530e-01,\n",
       "          7.49298334e-02,  6.41736994e-03,  6.71217963e-02,\n",
       "         -1.70064569e-02,  1.24861002e-01, -1.22372903e-01,\n",
       "         -2.81896312e-02,  4.34177630e-02, -1.40528167e-02,\n",
       "         -1.84720978e-02,  9.93404239e-02, -1.03559472e-01,\n",
       "          5.67738004e-02,  1.35951325e-01,  6.22235648e-02,\n",
       "         -1.10998154e-01,  9.89515036e-02,  2.06868183e-02,\n",
       "         -1.66165009e-01,  7.09635625e-03,  5.14702871e-02,\n",
       "          1.98793590e-01,  9.19209141e-03, -6.58706948e-02,\n",
       "          2.05540881e-01,  4.04223911e-02, -1.85666785e-01,\n",
       "         -2.67518237e-02,  8.53680000e-02,  1.72677830e-01,\n",
       "         -1.24157093e-01,  9.04001817e-02, -6.75361454e-02,\n",
       "          8.29505734e-03,  1.09373406e-01, -3.46668214e-02,\n",
       "          9.41560045e-03,  2.32476946e-02,  6.35932758e-02,\n",
       "          2.26589218e-02, -4.43968289e-02, -1.48331486e-02,\n",
       "          1.00406520e-01, -6.05840869e-02, -1.90835334e-02,\n",
       "          7.76514485e-02,  4.90037575e-02,  6.50226995e-02,\n",
       "          3.29912826e-02, -5.47534600e-02, -6.44710660e-02,\n",
       "         -1.12047851e-01, -3.25834453e-02,  1.04192533e-01,\n",
       "          4.49311920e-02,  9.44484305e-03,  8.00488442e-02,\n",
       "          6.82099536e-02, -1.75752193e-01, -1.04048578e-02,\n",
       "         -3.96705493e-02, -1.11624442e-01,  3.23037058e-02,\n",
       "          5.56433462e-02,  2.85835247e-02,  5.57955243e-02,\n",
       "          7.46684673e-04,  6.32935017e-02,  4.52117138e-02,\n",
       "         -6.46792576e-02,  7.01740906e-02, -1.99737415e-01,\n",
       "          7.13463305e-05, -2.39085168e-01,  3.82206291e-02,\n",
       "         -1.78653955e-01,  1.45309810e-02,  1.31432101e-01,\n",
       "          1.31974652e-01, -7.58276805e-02, -9.60861146e-03,\n",
       "         -2.35675946e-02,  1.03586346e-01, -1.48956820e-01,\n",
       "         -6.97204024e-02, -9.31221843e-02,  6.20310009e-02,\n",
       "          1.55842202e-02,  4.48270002e-03,  9.57056731e-02,\n",
       "          3.54722589e-02, -2.63722762e-02,  3.70257683e-02,\n",
       "         -9.60335210e-02, -9.23383832e-02]], dtype=float32)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_embeddings = create_input_image_embeddings()\n",
    "\n",
    "input_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_complete.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('./model/model_weights.h5')\n",
    "\n",
    "# Save the model architecture\n",
    "with open('./model/model_architecture.json', 'w') as f:\n",
    "    f.write(model.to_json())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
